
@dataclass
class LocationPoint:
    """Geographic location with validation."""
    latitude: float
    longitude: float
    street_name: str
    
    def __post_init__(self):
        if not -90 <= self.latitude <= 90:
            raise ValueError(f"Invalid latitude: {self.latitude}")
        if not -180 <= self.longitude <= 180:
            raise ValueError(f"Invalid longitude: {self.longitude}")

class EnvironmentalDataCollector:
    """Enterprise-grade environmental data collection system."""
    
    def __init__(self, database_path: str = "data/microclimate.db"):
        self.database_path = database_path
        self.db_connection = self._create_database()
        logger.info("Environmental data collector initialized")
    
    def _create_database(self) -> sqlite3.Connection:
        """Create optimized database schema."""
        Path(self.database_path).parent.mkdir(parents=True, exist_ok=True)
        conn = sqlite3.connect(self.database_path)
        cursor = conn.cursor()
        
        # Environmental measurements table
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS environmental_data (
            id INTEGER PRIMARY KEY,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            latitude REAL NOT NULL,
            longitude REAL NOT NULL,
            street_name TEXT,
            temperature_celsius REAL,
            humidity_percent REAL,
            air_quality_index INTEGER,
            wind_speed_ms REAL,
            comfort_index REAL,
            data_source TEXT
        )
        """)
        
        # Create geospatial index
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_location ON environmental_data(latitude, longitude)")
        conn.commit()
        return conn
    
    def collect_environmental_data(self, locations: List[LocationPoint]) -> pd.DataFrame:
        """Collect comprehensive environmental data from multiple sources."""
        logger.info(f"Collecting environmental data for {len(locations)} locations")
        
        environmental_data = []
        
        for i, location in enumerate(locations):
            try:
                # Simulate realistic weather data collection
                weather_data = self._collect_weather_data(location)
                air_quality_data = self._collect_air_quality_data(location)
                
                # Combine into comprehensive measurement
                measurement = {
                    'timestamp': datetime.now(),
                    'latitude': location.latitude,
                    'longitude': location.longitude,
                    'street_name': location.street_name,
                    'temperature_celsius': weather_data['temperature'],
                    'humidity_percent': weather_data['humidity'],
                    'wind_speed_ms': weather_data['wind_speed'],
                    'air_quality_index': air_quality_data['aqi'],
                    'data_source': 'multi_api_simulation'
                }
                
                # Calculate comfort index
                measurement['comfort_index'] = self._calculate_comfort_index(measurement)
                
                environmental_data.append(measurement)
                
                # Progress logging
                if (i + 1) % 2 == 0:
                    logger.info(f"Processed {i + 1}/{len(locations)} locations")
                
                time.sleep(0.1)  # Rate limiting
                
            except Exception as e:
                logger.error(f"Failed to collect data for {location.street_name}: {e}")
                continue
        
        # Convert to DataFrame and validate
        df = pd.DataFrame(environmental_data)
        if not df.empty:
            df = self._validate_data(df)
            self._save_to_database(df)
        
        logger.info(f"Successfully collected {len(df)} environmental measurements")
        return df
    
    def _collect_weather_data(self, location: LocationPoint) -> Dict:
        """Simulate realistic weather data collection with API patterns."""
        # Simulate seasonal temperature variation
        month = datetime.now().month
        base_temp = 15 + 10 * np.sin((month - 3) * np.pi / 6)
        
        # Add location-based variation
        if 'park' in location.street_name.lower():
            temp_adjustment = -2  # Parks are cooler
        elif 'financial' in location.street_name.lower():
            temp_adjustment = 3   # Urban heat island
        else:
            temp_adjustment = 0
        
        # Generate realistic weather with natural variation
        temperature = base_temp + temp_adjustment + np.random.normal(0, 3)
        humidity = np.clip(np.random.normal(60, 15), 30, 90)
        wind_speed = np.random.exponential(2)
        
        return {
            'temperature': round(temperature, 1),
            'humidity': round(humidity, 1),
            'wind_speed': round(wind_speed, 1)
        }
    
    def _collect_air_quality_data(self, location: LocationPoint) -> Dict:
        """Simulate air quality data with realistic urban patterns."""
        # Base AQI with urban/suburban differences
        if 'financial' in location.street_name.lower():
            base_aqi = 65  # Higher pollution in business districts
        elif 'park' in location.street_name.lower():
            base_aqi = 35  # Better air quality near parks
        else:
            base_aqi = 50  # Moderate baseline
        
        # Add temporal variation (rush hour effects)
        hour = datetime.now().hour
        if 7 <= hour <= 9 or 17 <= hour <= 19:
            rush_hour_bonus = np.random.normal(15, 5)
        else:
            rush_hour_bonus = 0
        
        aqi = np.clip(base_aqi + rush_hour_bonus + np.random.normal(0, 10), 10, 200)
        
        return {'aqi': int(round(aqi))}
    
    def _calculate_comfort_index(self, measurement: Dict) -> float:
        """Calculate environmental comfort index using domain expertise."""
        # Temperature comfort (optimal: 20Â°C)
        temp_comfort = max(0, 1 - abs(measurement['temperature_celsius'] - 20) / 15)
        
        # Humidity comfort (optimal: 50%)
        humidity_comfort = max(0, 1 - abs(measurement['humidity_percent'] - 50) / 50)
        
        # Air quality comfort (lower AQI is better)
        aqi_comfort = max(0, 1 - measurement['air_quality_index'] / 150)
        
        # Wind comfort (light breeze optimal: 2 m/s)
        wind_comfort = max(0, 1 - abs(measurement['wind_speed_ms'] - 2) / 5)
        
        # Weighted composite (based on environmental psychology research)
        comfort_index = (
            temp_comfort * 0.35 +
            aqi_comfort * 0.30 +
            humidity_comfort * 0.20 +
            wind_comfort * 0.15
        )
        
        return round(comfort_index, 3)
    
    def _validate_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """Apply data quality validation."""
        # Remove rows with invalid data
        df = df[
            (df['temperature_celsius'].between(-30, 50)) &
            (df['humidity_percent'].between(0, 100)) &
            (df['air_quality_index'].between(0, 300))
        ]
        
        # Remove duplicates
        df = df.drop_duplicates(subset=['latitude', 'longitude'])
        
        logger.info(f"Data validation: {len(df)} measurements passed quality checks")
        return df
    
    def _save_to_database(self, df: pd.DataFrame) -> None:
        """Persist data to database with error handling."""
        try:
            df.to_sql('environmental_data', self.db_connection, if_exists='append', index=False)
            logger.info(f"Saved {len(df)} measurements to database")
        except Exception as e:
            logger.error(f"Database save failed: {e}")


class BusinessDataCollector:
    """Professional business performance data collection and modeling."""
    
    def __init__(self):
        logger.info("Business data collector initialized")
    
    def generate_business_ecosystem(self, environmental_df: pd.DataFrame) -> pd.DataFrame:
        """Generate realistic business ecosystem with environmental correlations."""
        logger.info("Generating realistic business ecosystem")
        
        # Business categories with environmental sensitivity
        business_types = {
            'restaurant': {'probability': 0.25, 'env_sensitivity': 0.8},
            'cafe': {'probability': 0.15, 'env_sensitivity': 0.9},
            'retail': {'probability': 0.20, 'env_sensitivity': 0.6},
            'pharmacy': {'probability': 0.10, 'env_sensitivity': 0.3},
            'bank': {'probability': 0.10, 'env_sensitivity': 0.2},
            'fitness': {'probability': 0.10, 'env_sensitivity': 0.7},
            'salon': {'probability': 0.10, 'env_sensitivity': 0.5}
        }
        
        businesses = []
        business_id = 1
        
        for _, env_point in environmental_df.iterrows():
            # Generate 4-7 businesses per environmental point
            num_businesses = np.random.randint(4, 8)
            
            for i in range(num_businesses):
                # Select business type
                types = list(business_types.keys())
                weights = [business_types[t]['probability'] for t in types]
                business_type = np.random.choice(types, p=weights)
                
                # Generate business location near environmental point
                lat_offset = np.random.normal(0, 0.001)  # ~100m variation
                lon_offset = np.random.normal(0, 0.001)
                
                # Environmental impact on performance
                env_sensitivity = business_types[business_type]['env_sensitivity']
                env_bonus = self._calculate_environmental_impact(env_point, env_sensitivity)
                
                # Generate performance metrics
                performance = self._generate_performance_metrics(business_type, env_bonus)
                
                business = {
                    'business_id': f'BIZ_{business_id:05d}',
                    'name': f'{business_type.title()} #{business_id % 50}',
                    'category': business_type,
                    'latitude': env_point['latitude'] + lat_offset,
                    'longitude': env_point['longitude'] + lon_offset,
                    'measurement_area': env_point['street_name'],
                    'rating': performance['rating'],
                    'review_count': performance['reviews'],
                    'price_level': performance['price'],
                    'is_open': performance['operational'],
                    'success_score': performance['success_score'],
                    'env_sensitivity': env_sensitivity,
                    'env_bonus': env_bonus
                }
                
                businesses.append(business)
                business_id += 1
        
        business_df = pd.DataFrame(businesses)
        logger.info(f"Generated {len(business_df)} businesses in ecosystem")
        return business_df
    
    def _calculate_environmental_impact(self, env_data: pd.Series, sensitivity: float) -> float:
        """Calculate how environmental conditions affect business performance."""
        impact = 0.0
        
        # Temperature impact (optimal: 18-24Â°C)
        temp = env_data['temperature_celsius']
        if 18 <= temp <= 24:
            impact += 0.3
        elif 15 <= temp <= 27:
            impact += 0.1
        else:
            impact -= 0.2
        
        # Air quality impact
        aqi = env_data['air_quality_index']
        if aqi <= 50:
            impact += 0.2
        elif aqi <= 100:
            impact += 0.0
        else:
            impact -= 0.3
        
        # Apply business sensitivity
        return round(impact * sensitivity, 3)
    
    def _generate_performance_metrics(self, business_type: str, env_bonus: float) -> Dict:
        """Generate realistic business performance with environmental influence."""
        # Base performance by category
        base_metrics = {
            'restaurant': {'rating': 3.8, 'reviews': 85, 'price': 2},
            'cafe': {'rating': 4.1, 'reviews': 60, 'price': 2},
            'retail': {'rating': 3.6, 'reviews': 45, 'price': 2},
            'pharmacy': {'rating': 3.9, 'reviews': 25, 'price': 1},
            'bank': {'rating': 3.2, 'reviews': 15, 'price': 1},
            'fitness': {'rating': 4.0, 'reviews': 120, 'price': 3},
            'salon': {'rating': 4.2, 'reviews': 40, 'price': 2}
        }
        
        base = base_metrics.get(business_type, base_metrics['retail'])
        
        # Apply environmental bonus
        rating = np.clip(base['rating'] + env_bonus + np.random.normal(0, 0.3), 1.0, 5.0)
        
        # Reviews influenced by rating and environment
        review_multiplier = 1 + env_bonus + (rating - 3.5) * 0.2
        reviews = max(1, int(base['reviews'] * review_multiplier * np.random.uniform(0.7, 1.5)))
        
        # Calculate success score
        rating_score = (rating - 1) / 4
        review_score = np.log1p(reviews) / np.log1p(200)  # Normalize reviews
        success_score = (rating_score * 0.6 + review_score * 0.4)
        
        return {
            'rating': round(rating, 1),
            'reviews': reviews,
            'price': base['price'],
            'operational': np.random.choice([True, False], p=[0.9, 0.1]),
            'success_score': round(success_score, 3)
        }


def main_collection_pipeline():
    """Execute complete data collection pipeline."""
    logger.info("Starting Urban Micro-Climate Data Collection Pipeline")
    
    # Define sample locations for analysis
    locations = [
        LocationPoint(40.7128, -74.0060, 'Times Square Business District'),
        LocationPoint(40.7589, -73.9851, 'Central Park Commercial Zone'),
        LocationPoint(40.7505, -73.9934, 'Broadway Theater District'),
        LocationPoint(40.7282, -74.0776, 'Financial District'),
        LocationPoint(40.7831, -73.9712, 'Upper East Side Commercial')
    ]
    
    try:
        # Initialize collectors
        env_collector = EnvironmentalDataCollector()
        business_collector = BusinessDataCollector()
        
        # Collect data
        env_data = env_collector.collect_environmental_data(locations)
        business_data = business_collector.generate_business_ecosystem(env_data)
        
        logger.info("Data collection pipeline completed successfully")
        logger.info(f"Environmental measurements: {len(env_data)}")
        logger.info(f"Business profiles: {len(business_data)}")
        
        return env_data, business_data
        
    except Exception as e:
        logger.error(f"Pipeline failed: {e}")
        raise

if __name__ == "__main__":
    # Test the module
    env_df, biz_df = main_collection_pipeline()
    print(f"â Module 1 completed: {len(env_df)} env points, {len(biz_df)} businesses")
