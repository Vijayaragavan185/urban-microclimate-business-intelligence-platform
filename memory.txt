
    
    

    
    
    def build_predictive_model(self) -> Dict:
        """Build a predictive model for business success based on environmental factors."""
        if self.merged_data is None:
            raise ValueError("Merged data not available.")
        
        # Define features and target
        feature_columns = [
            'env_temperature', 'env_humidity', 'env_air_quality', 'env_wind_speed', 'env_comfort_index'
        ]
        target_column = 'business_success_score'
        
        # Filter for available columns
        available_features = [col for col in feature_columns if col in self.merged_data.columns]
        
        if target_column not in self.merged_data.columns:
            logger.warning("Target variable not available for modeling")
            return {}
        
        # Prepare data
        model_data = self.merged_data[available_features + [target_column]].dropna()
        
        if len(model_data) < 10:
            logger.warning("Insufficient data for predictive modeling")
            return {}
        
        X = model_data[available_features]
        y = model_data[target_column]
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
        
        # Train Random Forest model
        rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
        rf_model.fit(X_train, y_train)
        
        # Make predictions
        y_pred = rf_model.predict(X_test)
        
        # Calculate metrics
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        # Feature importance
        feature_importance = dict(zip(available_features, rf_model.feature_importances_))
        
        model_results = {
            'model_type': 'Random Forest Regression',
            'training_samples': len(X_train),
            'test_samples': len(X_test),
            'mse': mse,
            'rmse': np.sqrt(mse),
            'r2_score': r2,
            'feature_importance': feature_importance,
            'model_object': rf_model,
            'scaler_object': None  # Could add feature scaling if needed
        }
        
        logger.info(f"Predictive model built: RÂ² = {r2:.3f}, RMSE = {np.sqrt(mse):.3f}")
        return model_results
    
    def analyze_business_performance_by_environment(self) -> Dict:
        """Analyze business performance patterns across different environmental conditions."""
        if self.merged_data is None:
            raise ValueError("Merged data not available.")
        
        performance_analysis = {}
        
        # Analysis by environmental comfort levels
        if 'env_comfort_index' in self.merged_data.columns:
            # Create comfort categories
            comfort_data = self.merged_data.copy()
            comfort_data['comfort_category'] = pd.cut(
                comfort_data['env_comfort_index'],
                bins=[0, 0.3, 0.6, 0.8, 1.0],
                labels=['Poor', 'Fair', 'Good', 'Excellent'],
                include_lowest=True
            )
            
            # Calculate performance metrics by comfort category
            comfort_performance = comfort_data.groupby('comfort_category').agg({
                'business_success_score': ['count', 'mean', 'std'],
                'business_rating': ['mean', 'std'],
                'business_reviews': ['mean', 'median']
            }).round(3)
            
            performance_analysis['by_comfort_level'] = comfort_performance.to_dict()
        
        # Analysis by air quality levels
        if 'env_air_quality' in self.merged_data.columns:
            aqi_data = self.merged_data.copy()
            aqi_data['aqi_category'] = pd.cut(
                aqi_data['env_air_quality'],
                bins=[0, 50, 100, 150, 300],
                labels=['Good', 'Moderate', 'Unhealthy', 'Very Unhealthy'],
                include_lowest=True
            )
            
            aqi_performance = aqi_data.groupby('aqi_category').agg({
                'business_success_score': ['count', 'mean', 'std'],
                'business_rating': ['mean', 'std']
            }).round(3)
            
            performance_analysis['by_air_quality'] = aqi_performance.to_dict()
        
        # Analysis by temperature ranges
        if 'env_temperature' in self.merged_data.columns:
            temp_data = self.merged_data.copy()
            temp_data['temp_category'] = pd.cut(
                temp_data['env_temperature'],
                bins=[-np.inf, 15, 20, 25, np.inf],
                labels=['Cold', 'Cool', 'Moderate', 'Warm'],
                include_lowest=True
            )
            
            temp_performance = temp_data.groupby('temp_category').agg({
                'business_success_score': ['count', 'mean', 'std'],
                'business_rating': ['mean', 'std']
            }).round(3)
            
            performance_analysis['by_temperature'] = temp_performance.to_dict()
        
        # Business category analysis
        if 'business_category' in self.merged_data.columns:
            category_performance = self.merged_data.groupby('business_category').agg({
                'business_success_score': ['count', 'mean', 'std'],
                'business_rating': ['mean', 'std'],
                'env_comfort_index': ['mean', 'std']
            }).round(3)
            
            performance_analysis['by_business_category'] = category_performance.to_dict()
        
        logger.info("Business performance analysis by environment completed")
        return performance_analysis
    
    def generate_business_insights(self) -> Dict:
        """Generate actionable business insights from the analysis."""
        if self.merged_data is None:
            raise ValueError("Merged data not available.")
        
        insights = {
            'summary_statistics': {},
            'key_findings': [],
            'recommendations': [],
            'risk_factors': [],
            'opportunities': []
        }
        
        # Summary statistics
        if 'business_success_score' in self.merged_data.columns:
            insights['summary_statistics']['total_businesses'] = len(self.merged_data)
            insights['summary_statistics']['avg_success_score'] = self.merged_data['business_success_score'].mean()
            insights['summary_statistics']['success_std'] = self.merged_data['business_success_score'].std()
        
        if 'env_comfort_index' in self.merged_data.columns:
            insights['summary_statistics']['avg_comfort_index'] = self.merged_data['env_comfort_index'].mean()
            insights['summary_statistics']['comfort_std'] = self.merged_data['env_comfort_index'].std()
        
        # Identify high and low performers
        if 'business_success_score' in self.merged_data.columns:
            high_performers = self.merged_data[self.merged_data['business_success_score'] > 0.7]
            low_performers = self.merged_data[self.merged_data['business_success_score'] < 0.3]
            
            insights['summary_statistics']['high_performers_count'] = len(high_performers)
            insights['summary_statistics']['low_performers_count'] = len(low_performers)
            
            if len(high_performers) > 0 and 'env_comfort_index' in self.merged_data.columns:
                avg_comfort_high = high_performers['env_comfort_index'].mean()
                insights['key_findings'].append(
                    f"High-performing businesses (success score > 0.7) operate in areas with average comfort index of {avg_comfort_high:.3f}"
                )
            
            if len(low_performers) > 0 and 'env_comfort_index' in self.merged_data.columns:
                avg_comfort_low = low_performers['env_comfort_index'].mean()
                insights['key_findings'].append(
                    f"Low-performing businesses (success score < 0.3) operate in areas with average comfort index of {avg_comfort_low:.3f}"
                )
        
        # Environmental recommendations
        if 'env_comfort_index' in self.merged_data.columns and 'business_success_score' in self.merged_data.columns:
            comfort_success_corr = self.merged_data['env_comfort_index'].corr(self.merged_data['business_success_score'])
            
            if comfort_success_corr > 0.3:
                insights['recommendations'].append(
                    "Prioritize locations with high environmental comfort index for new business ventures"
                )
                insights['recommendations'].append(
                    "Consider environmental improvements (air quality, temperature control) to boost business performance"
                )
            
            if comfort_success_corr < -0.3:
                insights['risk_factors'].append(
                    "Negative correlation between environmental comfort and business success detected - investigate further"
                )
        
        # Air quality insights
        if 'env_air_quality' in self.merged_data.columns and 'business_rating' in self.merged_data.columns:
            aqi_rating_corr = self.merged_data['env_air_quality'].corr(self.merged_data['business_rating'])
            
            if aqi_rating_corr < -0.2:
                insights['key_findings'].append(
                    "Poor air quality negatively correlates with business ratings"
                )
                insights['recommendations'].append(
                    "Consider air quality when selecting business locations, especially for customer-facing businesses"
                )
        
        # Category-specific insights
        if 'business_category' in self.merged_data.columns:
            category_performance = self.merged_data.groupby('business_category')['business_success_score'].mean()
            best_category = category_performance.idxmax()
            worst_category = category_performance.idxmin()
            
            insights['key_findings'].append(
                f"Best performing business category: {best_category} (avg success: {category_performance[best_category]:.3f})"
            )
            insights['key_findings'].append(
                f"Lowest performing business category: {worst_category} (avg success: {category_performance[worst_category]:.3f})"
            )
        
        # Opportunities
        if 'env_comfort_index' in self.merged_data.columns:
            high_comfort_areas = self.merged_data[self.merged_data['env_comfort_index'] > 0.8]
            if len(high_comfort_areas) > 0:
                insights['opportunities'].append(
                    f"Identified {len(high_comfort_areas)} high-comfort locations with potential for business development"
                )
        
        logger.info("Business insights generation completed")
        return insights
    
    def run_comprehensive_analysis(self, env_file: str = None, business_file: str = None) -> AnalysisResults:
        """Run the complete business performance analysis pipeline."""
        logger.info("Starting comprehensive business performance analysis")
        
        # Load data
        if env_file and business_file:
            self.load_data_from_csv(env_file, business_file)
        else:
            try:
                self.load_data_from_database()
            except:
                logger.warning("Could not load from database, using simulated data")
                self._generate_sample_data()
        
        # Perform spatial merge
        self.spatial_merge_datasets()
        
        # Run all analyses
        correlation_matrix = self.calculate_correlation_matrix()
        statistical_tests = self.perform_statistical_significance_tests()
        cluster_analysis = self.perform_cluster_analysis()
        predictive_model = self.build_predictive_model()
        performance_analysis = self.analyze_business_performance_by_environment()
        business_insights = self.generate_business_insights()
        
        # Compile results
        results = AnalysisResults(
            correlation_matrix=correlation_matrix,
            statistical_tests=statistical_tests,
            cluster_analysis=cluster_analysis,
            performance_metrics=predictive_model,
            business_insights=business_insights
        )
        
        # Store results for later access
        self.analysis_results = {
            'correlation_matrix': correlation_matrix,
            'statistical_tests': statistical_tests,
            'cluster_analysis': cluster_analysis,
            'predictive_model': predictive_model,
            'performance_analysis': performance_analysis,
            'business_insights': business_insights
        }
        
        logger.info("Comprehensive analysis completed successfully")
        return results
    
    def _generate_sample_data(self):
        """Generate sample data for testing when real data is not available."""
        # Generate sample environmental data
        np.random.seed(42)
        n_env_points = 7
        
        env_data = []
        for i in range(n_env_points):
            env_point = {
                'id': i + 1,
                'latitude': 40.7128 + np.random.normal(0, 0.01),
                'longitude': -74.0060 + np.random.normal(0, 0.01),
                'street_name': f'Test Area {i+1}',
                'temperature_celsius': 20 + np.random.normal(0, 5),
                'humidity_percent': 60 + np.random.normal(0, 15),
                'air_quality_index': 50 + np.random.normal(0, 20),
                'wind_speed_ms': 2 + np.random.exponential(1),
                'comfort_index': np.random.uniform(0.3, 0.9),
                'quality_score': np.random.uniform(0.7, 1.0)
            }
            env_data.append(env_point)
        
        self.env_data = pd.DataFrame(env_data)
        
        # Generate sample business data
        business_data = []
        business_id = 1
        
        for _, env_point in self.env_data.iterrows():
            n_businesses = np.random.randint(3, 8)
            
            for j in range(n_businesses):
                # Environmental influence on business performance
                env_bonus = (env_point['comfort_index'] - 0.5) * 0.4
                
                rating = 3.5 + env_bonus + np.random.normal(0, 0.5)
                rating = np.clip(rating, 1, 5)
                
                reviews = int(50 * (1 + env_bonus) * np.random.uniform(0.5, 2))
                success_score = (rating - 1) / 4 * 0.6 + np.log1p(reviews) / np.log1p(200) * 0.4
                
                business = {
                    'business_id': f'BIZ_{business_id:03d}',
                    'name': f'Business {business_id}',
                    'category': np.random.choice(['restaurant', 'cafe', 'retail', 'fitness']),
                    'latitude': env_point['latitude'] + np.random.normal(0, 0.001),
                    'longitude': env_point['longitude'] + np.random.normal(0, 0.001),
                    'rating': round(rating, 1),
                    'review_count': reviews,
                    'success_score': round(success_score, 3),
                    'price_level': np.random.randint(1, 5),
                    'is_open': np.random.choice([True, False], p=[0.9, 0.1])
                }
                
                business_data.append(business)
                business_id += 1
        
        self.business_data = pd.DataFrame(business_data)
        
        logger.info(f"Generated sample data: {len(self.env_data)} env points, {len(self.business_data)} businesses")


def main_analysis_pipeline():
    """Execute the complete business analysis pipeline."""
    analyzer = BusinessPerformanceAnalyzer()
    
    try:
        # Run comprehensive analysis
        results = analyzer.run_comprehensive_analysis()
        
        # Print key results
        print("\\n=== BUSINESS PERFORMANCE ANALYSIS RESULTS ===")
        print(f"Merged dataset size: {len(analyzer.merged_data)} business-environment pairs")
        
        # Statistical tests
        if results.statistical_tests:
            print("\\n--- Statistical Significance Tests ---")
            for test_name, test_result in results.statistical_tests.items():
                print(f"{test_name}: {test_result['interpretation']}")
        
        # Cluster analysis
        if results.cluster_analysis:
            print(f"\\n--- Cluster Analysis ---")
            print(f"Identified {results.cluster_analysis['n_clusters']} environmental-business clusters")
            print(f"Outliers detected: {results.cluster_analysis['n_outliers']}")
        
        # Business insights
        if results.business_insights:
            print("\\n--- Key Business Insights ---")
            for finding in results.business_insights.get('key_findings', []):
                print(f"â¢ {finding}")
        
        return results
        
    except Exception as e:
        logger.error(f"Analysis pipeline failed: {e}")
        raise


if __name__ == "__main__":
    results = main_analysis_pipeline()
    print("\\nâ Business analysis module completed successfully!")



